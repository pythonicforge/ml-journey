{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684f643e-c630-46da-a6d7-be3176ad02d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8532d9dc-db1c-43f3-8882-359f02a685f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8656bcd0-0c63-4b6a-bbfa-9500e1ba691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f48804f-eaa1-468f-9704-f8f10a5ac685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6517cd-2506-4830-8b41-784a1774fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Activation function\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z) #So this function just checks if the number is greater then 0 or less than euqal to 0. and returns the desired maximum.\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True) \n",
    "\n",
    "# Forward propagation function\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# One hot encoding logic\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max()+1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def deriv_ReLU(Z):\n",
    "    return Z > 0\n",
    "\n",
    "# Backward propagation function\n",
    "def backward_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = 2*(A2 - one_hot_Y)\n",
    "    dW2 = (1 / m) * dZ2.dot(A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "    dW1 = (1 / m) * dZ1.dot(X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * np.reshape(db1, (10,1))\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * np.reshape(db2, (10,1))\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20fe8ad-128d-4ce8-bc5e-7e541640eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    # print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "    \n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        loss = -np.mean(Y * np.log(A2 + 1e-8))  # Cross-entropy loss\n",
    "        accuracy = get_accuracy(get_predictions(A2), Y)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c227c3e-3bb5-4247-8a3a-729e0b5912d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.0745098 , 0.05490196, 0.03137255, 0.36470588,\n",
       "         0.55686275, 0.55686275, 0.64705882, 0.61176471, 0.6       ,\n",
       "         0.49803922, 0.23529412, 0.01568627, 0.0745098 , 0.06666667,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01568627, 0.04705882, 0.09411765, 0.6       , 0.4627451 ,\n",
       "         0.14509804, 0.03921569, 0.03529412, 0.05490196, 0.13333333,\n",
       "         0.27843137, 0.5372549 , 0.37254902, 0.03137255, 0.0745098 ,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00392157, 0.05882353, 0.61960784, 0.30588235, 0.        ,\n",
       "         0.05098039, 0.07843137, 0.0745098 , 0.07058824, 0.05490196,\n",
       "         0.01568627, 0.00784314, 0.49411765, 0.14509804, 0.04705882,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "         0.        , 0.48627451, 0.34901961, 0.        , 0.09411765,\n",
       "         0.07058824, 0.06666667, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.09019608, 0.01960784, 0.31372549, 0.31372549, 0.01568627,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03921569, 0.58039216, 0.05490196, 0.0745098 , 0.06666667,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.0745098 , 0.03137255, 0.23137255, 0.46666667, 0.01176471,\n",
       "         0.08235294, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "         0.14509804, 0.51764706, 0.01960784, 0.07843137, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.04705882, 0.14901961, 0.49019608, 0.03137255,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "         0.20392157, 0.4745098 , 0.00784314, 0.08235294, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.04705882, 0.16078431, 0.51372549, 0.03137255,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "         0.14117647, 0.5254902 , 0.01960784, 0.07843137, 0.06666667,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.04705882, 0.16078431, 0.51372549, 0.03137255,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01960784, 0.56862745, 0.10196078, 0.0627451 , 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.05098039, 0.15294118, 0.5372549 , 0.02745098,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "         0.        , 0.49019608, 0.25490196, 0.01176471, 0.08235294,\n",
       "         0.06666667, 0.07058824, 0.07058824, 0.07058824, 0.06666667,\n",
       "         0.09019608, 0.        , 0.41960784, 0.41960784, 0.00784314,\n",
       "         0.07843137, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.21176471, 0.62745098, 0.05490196, 0.05882353,\n",
       "         0.08235294, 0.06666667, 0.06666667, 0.07058824, 0.09019608,\n",
       "         0.        , 0.23529412, 0.63137255, 0.04705882, 0.07058824,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01960784, 0.01568627, 0.30196078, 0.55686275, 0.03529412,\n",
       "         0.01960784, 0.0745098 , 0.08235294, 0.07843137, 0.        ,\n",
       "         0.27843137, 0.64705882, 0.1254902 , 0.04705882, 0.0745098 ,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.08235294, 0.        , 0.27843137, 0.57254902,\n",
       "         0.23921569, 0.05882353, 0.00392157, 0.01568627, 0.42352941,\n",
       "         0.61568627, 0.08627451, 0.03921569, 0.07843137, 0.06666667,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.08235294, 0.02352941, 0.18039216,\n",
       "         0.48627451, 0.52941176, 0.38431373, 0.6745098 , 0.4745098 ,\n",
       "         0.01176471, 0.02352941, 0.08235294, 0.0745098 , 0.06666667,\n",
       "         0.07058824, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.06666667, 0.07843137, 0.04705882,\n",
       "         0.        , 0.14509804, 0.77254902, 0.5254902 , 0.47843137,\n",
       "         0.4745098 , 0.25098039, 0.03137255, 0.03921569, 0.08235294,\n",
       "         0.06666667, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.07058824, 0.07058824, 0.0745098 ,\n",
       "         0.04705882, 0.58039216, 0.25882353, 0.        , 0.10588235,\n",
       "         0.25098039, 0.45098039, 0.54901961, 0.16862745, 0.01960784,\n",
       "         0.08235294, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.06666667, 0.08235294, 0.        ,\n",
       "         0.49019608, 0.38431373, 0.        , 0.09803922, 0.0627451 ,\n",
       "         0.02745098, 0.        , 0.18823529, 0.60784314, 0.25882353,\n",
       "         0.01960784, 0.08235294, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.08235294, 0.00784314, 0.35294118,\n",
       "         0.55294118, 0.01176471, 0.08235294, 0.06666667, 0.07058824,\n",
       "         0.0745098 , 0.08627451, 0.02745098, 0.06666667, 0.63529412,\n",
       "         0.14117647, 0.03921569, 0.01568627, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.07058824, 0.05098039, 0.14117647, 0.63529412,\n",
       "         0.05490196, 0.0627451 , 0.07058824, 0.06666667, 0.07058824,\n",
       "         0.07058824, 0.06666667, 0.08235294, 0.03137255, 0.2       ,\n",
       "         0.54509804, 0.05098039, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.08235294, 0.        , 0.48235294, 0.32941176,\n",
       "         0.00784314, 0.08235294, 0.06666667, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.06666667, 0.08235294, 0.00392157,\n",
       "         0.30196078, 0.42745098, 0.        , 0.00784314, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.0745098 , 0.56862745, 0.09019608,\n",
       "         0.0627451 , 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.06666667, 0.0745098 ,\n",
       "         0.05490196, 0.5254902 , 0.03137255, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01176471, 0.03921569, 0.19215686, 0.54901961, 0.02352941,\n",
       "         0.07843137, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.07058824, 0.07843137,\n",
       "         0.01568627, 0.45882353, 0.16078431, 0.        , 0.00392157,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01568627, 0.02745098, 0.23921569, 0.52156863, 0.01176471,\n",
       "         0.08235294, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.07058824, 0.06666667, 0.07843137,\n",
       "         0.03529412, 0.52941176, 0.10980392, 0.        , 0.00392157,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01176471, 0.03137255, 0.22745098, 0.5372549 , 0.01568627,\n",
       "         0.07843137, 0.07058824, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07058824, 0.06666667, 0.07843137, 0.05098039,\n",
       "         0.15294118, 0.5372549 , 0.        , 0.00392157, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01176471, 0.04705882, 0.16078431, 0.55686275, 0.03137255,\n",
       "         0.07843137, 0.06666667, 0.07058824, 0.07058824, 0.07058824,\n",
       "         0.07058824, 0.07843137, 0.0745098 , 0.03921569, 0.        ,\n",
       "         0.50196078, 0.31764706, 0.        , 0.00392157, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.07058824, 0.04705882, 0.59607843, 0.14117647,\n",
       "         0.03921569, 0.08235294, 0.07843137, 0.0745098 , 0.07058824,\n",
       "         0.04313725, 0.01176471, 0.03921569, 0.22352941, 0.5372549 ,\n",
       "         0.51372549, 0.02745098, 0.01568627, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.07843137, 0.02352941, 0.28235294, 0.56470588,\n",
       "         0.02745098, 0.02745098, 0.02745098, 0.03529412, 0.06666667,\n",
       "         0.16862745, 0.34509804, 0.53333333, 0.52941176, 0.28235294,\n",
       "         0.04313725, 0.06666667, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.00784314, 0.06666667, 0.07843137, 0.01568627, 0.38823529,\n",
       "         0.56078431, 0.43137255, 0.45098039, 0.47058824, 0.50588235,\n",
       "         0.4627451 , 0.32941176, 0.14509804, 0.00784314, 0.01568627,\n",
       "         0.0745098 , 0.07058824, 0.00784314, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array / 255.0\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    return image_array\n",
    "\n",
    "img_arr = preprocess_image(\"rsz_image_editor.png\")\n",
    "img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749fad35-57c9-4174-be59-d6b403576aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(img_arr[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2c8bdaa-7a90-4757-9839-3d781db3b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Loss: 14.5017, Accuracy: 0.1163\n",
      "Iteration 100 - Loss: 11.0290, Accuracy: 0.2665\n",
      "Iteration 200 - Loss: 11.5441, Accuracy: 0.3644\n",
      "Iteration 300 - Loss: 12.3170, Accuracy: 0.4182\n",
      "Iteration 400 - Loss: 13.1963, Accuracy: 0.4598\n",
      "Iteration 500 - Loss: 14.2461, Accuracy: 0.5020\n",
      "Iteration 600 - Loss: 15.5039, Accuracy: 0.5500\n",
      "Iteration 700 - Loss: 16.8683, Accuracy: 0.5904\n",
      "Iteration 800 - Loss: 18.2594, Accuracy: 0.6284\n",
      "Iteration 900 - Loss: 19.6204, Accuracy: 0.6572\n",
      "Iteration 1000 - Loss: 20.9082, Accuracy: 0.6813\n",
      "Iteration 1100 - Loss: 22.0944, Accuracy: 0.7025\n",
      "Iteration 1200 - Loss: 23.1716, Accuracy: 0.7217\n",
      "Iteration 1300 - Loss: 24.1525, Accuracy: 0.7370\n",
      "Iteration 1400 - Loss: 25.0605, Accuracy: 0.7523\n",
      "Iteration 1500 - Loss: 25.9112, Accuracy: 0.7652\n",
      "Iteration 1600 - Loss: 26.7057, Accuracy: 0.7776\n",
      "Iteration 1700 - Loss: 27.4375, Accuracy: 0.7888\n",
      "Iteration 1800 - Loss: 28.1004, Accuracy: 0.7975\n",
      "Iteration 1900 - Loss: 28.6989, Accuracy: 0.8055\n",
      "Iteration 2000 - Loss: 29.2391, Accuracy: 0.8119\n",
      "Iteration 2100 - Loss: 29.7270, Accuracy: 0.8175\n",
      "Iteration 2200 - Loss: 30.1669, Accuracy: 0.8222\n",
      "Iteration 2300 - Loss: 30.5629, Accuracy: 0.8273\n",
      "Iteration 2400 - Loss: 30.9243, Accuracy: 0.8320\n",
      "Iteration 2500 - Loss: 31.2544, Accuracy: 0.8353\n",
      "Iteration 2600 - Loss: 31.5583, Accuracy: 0.8390\n",
      "Iteration 2700 - Loss: 31.8431, Accuracy: 0.8426\n",
      "Iteration 2800 - Loss: 32.1094, Accuracy: 0.8452\n",
      "Iteration 2900 - Loss: 32.3574, Accuracy: 0.8482\n",
      "Iteration 3000 - Loss: 32.5914, Accuracy: 0.8505\n",
      "Iteration 3100 - Loss: 32.8105, Accuracy: 0.8530\n",
      "Iteration 3200 - Loss: 33.0184, Accuracy: 0.8548\n",
      "Iteration 3300 - Loss: 33.2144, Accuracy: 0.8569\n",
      "Iteration 3400 - Loss: 33.4010, Accuracy: 0.8587\n",
      "Iteration 3500 - Loss: 33.5799, Accuracy: 0.8604\n",
      "Iteration 3600 - Loss: 33.7481, Accuracy: 0.8622\n",
      "Iteration 3700 - Loss: 33.9049, Accuracy: 0.8637\n",
      "Iteration 3800 - Loss: 34.0527, Accuracy: 0.8654\n",
      "Iteration 3900 - Loss: 34.1924, Accuracy: 0.8669\n",
      "Iteration 4000 - Loss: 34.3256, Accuracy: 0.8681\n",
      "Iteration 4100 - Loss: 34.4530, Accuracy: 0.8697\n",
      "Iteration 4200 - Loss: 34.5746, Accuracy: 0.8710\n",
      "Iteration 4300 - Loss: 34.6907, Accuracy: 0.8721\n",
      "Iteration 4400 - Loss: 34.8005, Accuracy: 0.8736\n",
      "Iteration 4500 - Loss: 34.9060, Accuracy: 0.8748\n",
      "Iteration 4600 - Loss: 35.0073, Accuracy: 0.8760\n",
      "Iteration 4700 - Loss: 35.1058, Accuracy: 0.8770\n",
      "Iteration 4800 - Loss: 35.2011, Accuracy: 0.8782\n",
      "Iteration 4900 - Loss: 35.2929, Accuracy: 0.8791\n",
      "Iteration 5000 - Loss: 35.3813, Accuracy: 0.8800\n",
      "Iteration 5100 - Loss: 35.4669, Accuracy: 0.8810\n",
      "Iteration 5200 - Loss: 35.5490, Accuracy: 0.8816\n",
      "Iteration 5300 - Loss: 35.6281, Accuracy: 0.8826\n",
      "Iteration 5400 - Loss: 35.7040, Accuracy: 0.8833\n",
      "Iteration 5500 - Loss: 35.7785, Accuracy: 0.8840\n",
      "Iteration 5600 - Loss: 35.8520, Accuracy: 0.8847\n",
      "Iteration 5700 - Loss: 35.9231, Accuracy: 0.8853\n",
      "Iteration 5800 - Loss: 35.9924, Accuracy: 0.8861\n",
      "Iteration 5900 - Loss: 36.0581, Accuracy: 0.8867\n",
      "Iteration 6000 - Loss: 36.1218, Accuracy: 0.8873\n",
      "Iteration 6100 - Loss: 36.1844, Accuracy: 0.8882\n",
      "Iteration 6200 - Loss: 36.2463, Accuracy: 0.8890\n",
      "Iteration 6300 - Loss: 36.3069, Accuracy: 0.8896\n",
      "Iteration 6400 - Loss: 36.3653, Accuracy: 0.8904\n",
      "Iteration 6500 - Loss: 36.4216, Accuracy: 0.8908\n",
      "Iteration 6600 - Loss: 36.4751, Accuracy: 0.8910\n",
      "Iteration 6700 - Loss: 36.5267, Accuracy: 0.8916\n",
      "Iteration 6800 - Loss: 36.5761, Accuracy: 0.8920\n",
      "Iteration 6900 - Loss: 36.6245, Accuracy: 0.8925\n",
      "Iteration 7000 - Loss: 36.6729, Accuracy: 0.8929\n",
      "Iteration 7100 - Loss: 36.7207, Accuracy: 0.8934\n",
      "Iteration 7200 - Loss: 36.7674, Accuracy: 0.8941\n",
      "Iteration 7300 - Loss: 36.8135, Accuracy: 0.8946\n",
      "Iteration 7400 - Loss: 36.8587, Accuracy: 0.8949\n",
      "Iteration 7500 - Loss: 36.9027, Accuracy: 0.8955\n",
      "Iteration 7600 - Loss: 36.9445, Accuracy: 0.8959\n",
      "Iteration 7700 - Loss: 36.9842, Accuracy: 0.8962\n",
      "Iteration 7800 - Loss: 37.0229, Accuracy: 0.8966\n",
      "Iteration 7900 - Loss: 37.0620, Accuracy: 0.8972\n",
      "Iteration 8000 - Loss: 37.1009, Accuracy: 0.8976\n",
      "Iteration 8100 - Loss: 37.1400, Accuracy: 0.8979\n",
      "Iteration 8200 - Loss: 37.1789, Accuracy: 0.8983\n",
      "Iteration 8300 - Loss: 37.2174, Accuracy: 0.8989\n",
      "Iteration 8400 - Loss: 37.2553, Accuracy: 0.8993\n",
      "Iteration 8500 - Loss: 37.2919, Accuracy: 0.8997\n",
      "Iteration 8600 - Loss: 37.3281, Accuracy: 0.9002\n",
      "Iteration 8700 - Loss: 37.3635, Accuracy: 0.9008\n",
      "Iteration 8800 - Loss: 37.3986, Accuracy: 0.9013\n",
      "Iteration 8900 - Loss: 37.4335, Accuracy: 0.9015\n",
      "Iteration 9000 - Loss: 37.4670, Accuracy: 0.9019\n",
      "Iteration 9100 - Loss: 37.5003, Accuracy: 0.9023\n",
      "Iteration 9200 - Loss: 37.5325, Accuracy: 0.9024\n",
      "Iteration 9300 - Loss: 37.5646, Accuracy: 0.9027\n",
      "Iteration 9400 - Loss: 37.5977, Accuracy: 0.9028\n",
      "Iteration 9500 - Loss: 37.6308, Accuracy: 0.9030\n",
      "Iteration 9600 - Loss: 37.6638, Accuracy: 0.9031\n",
      "Iteration 9700 - Loss: 37.6960, Accuracy: 0.9037\n",
      "Iteration 9800 - Loss: 37.7275, Accuracy: 0.9041\n",
      "Iteration 9900 - Loss: 37.7584, Accuracy: 0.9045\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a0574-1b40-41fd-9265-3e16515fb789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a419c58-6e75-4436-ae69-c3a376e09172",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,784) and (1,1,28) not aligned: 784 (dim 1) != 1 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_prediction(\u001b[38;5;241m7\u001b[39m, W1, b1, W2, b2)\n\u001b[1;32m      2\u001b[0m test_prediction(\u001b[38;5;241m4\u001b[39m, W1, b1, W2, b2)\n\u001b[1;32m      3\u001b[0m test_prediction(\u001b[38;5;241m5\u001b[39m, W1, b1, W2, b2)\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36mtest_prediction\u001b[0;34m(index, W1, b1, W2, b2)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_prediction\u001b[39m(index, W1, b1, W2, b2):\n\u001b[1;32m      7\u001b[0m     current_image \u001b[38;5;241m=\u001b[39m X_train[:, index, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m----> 8\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m make_predictions(img_arr[:, index, \u001b[38;5;28;01mNone\u001b[39;00m], W1, b1, W2, b2)\n\u001b[1;32m      9\u001b[0m     label \u001b[38;5;241m=\u001b[39m Y_train[index]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mmake_predictions\u001b[0;34m(X, W1, b1, W2, b2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_predictions\u001b[39m(X, W1, b1, W2, b2):\n\u001b[0;32m----> 2\u001b[0m     _, _, _, A2 \u001b[38;5;241m=\u001b[39m forward_prop(W1, b1, W2, b2, X)\n\u001b[1;32m      3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mforward_prop\u001b[0;34m(W1, b1, W2, b2, X)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_prop\u001b[39m(W1, b1, W2, b2, X):\n\u001b[0;32m---> 18\u001b[0m     Z1 \u001b[38;5;241m=\u001b[39m W1\u001b[38;5;241m.\u001b[39mdot(X) \u001b[38;5;241m+\u001b[39m b1\n\u001b[1;32m     19\u001b[0m     A1 \u001b[38;5;241m=\u001b[39m ReLU(Z1)\n\u001b[1;32m     20\u001b[0m     Z2 \u001b[38;5;241m=\u001b[39m W2\u001b[38;5;241m.\u001b[39mdot(A1) \u001b[38;5;241m+\u001b[39m b2\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,784) and (1,1,28) not aligned: 784 (dim 1) != 1 (dim 1)"
     ]
    }
   ],
   "source": [
    "test_prediction(7, W1, b1, W2, b2)\n",
    "test_prediction(4, W1, b1, W2, b2)\n",
    "test_prediction(5, W1, b1, W2, b2)\n",
    "test_prediction(8, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66eaf14-f01f-4ae4-aa78-b39bc8115103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
